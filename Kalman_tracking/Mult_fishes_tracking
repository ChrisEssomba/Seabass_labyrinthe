#The pfg algorithm applied to my model
 
# -*- coding: utf-8 -*-
 
from gettext import install
from itertools import islice
import math
from random import randint
import cv2
from matplotlib import pyplot as plt
from ultralytics import YOLO
# import some common libraries
from filterpy.kalman import KalmanFilter as kf
# import some common libraries
import numpy as np

 
#dict_bb = {}
# Load the YOLO model and video
model = YOLO("D:/Chris/LabirintoLubinas/best.pt")
 
# Load the video
video = cv2.VideoCapture("D:\Chris\LabirintoLubinas\cortado_laberinto2.mp4")

# Get the video fps
fps = video.get(cv2.CAP_PROP_FPS)

# Create bounding boxes colors
colors = [
    (255, 0, 0),   # Blue
    (255, 255, 255), # White
    (0, 0, 0),     # Black
    (0, 0, 255),   # Red
    (0, 255, 0)    # Green
]

#Generate the resolution of the output video
width = 1920
height = 1080
res = (int(width), int(height))  
 
# Define the function that returns bounding boxes position and confidence score
def detect_objects(image):
    outputs = model(image)
    boxes = outputs[0].boxes
    dict_bb = {}
    scores = {}
 
    for idx, box in enumerate(boxes):
        if idx >= 5:
            break
        dict_bb[idx] = box.xyxy[0].tolist()  # Mapping for each bounding box coordinate to an index
        scores[idx] = box.conf[0].item()
 
    return dict_bb, scores
 
# Initialize the Kalman filter variables
kalman_list = []
medidas = []
col_caja = []
mostrar = []
DictX = {}
DictY = {}
id = []
borrar = []
anteriores = []
lost_occurence = {}
dt = 1 / fps  # La cámara empleada es de 15 fps
lost_id=0

# Configurar el video de salida
out = cv2.VideoWriter('D:/Chris/2023_PFG_Daniel_Areñas_Mayoral/Multi_kalman2.avi', cv2.VideoWriter_fourcc(*'DIVX'), 15, res)

#Bounding boxes from the precedding frame
prev_box = {}

#Bounding boxes number of the preceeding frame
prev_length = 0

posicion_key ={}

#occurence of each bounding box 
lost_occurence2 = {0:0,
         1:0,
         2:0,
         3:0,
         4:0}
#breaks = 0

while video.isOpened():
    #Read the frame
    ok, frame = video.read()  
    
    if not ok:
        break
    associated_bb = {}
    associated_bb2 = []
    # Resize the frame
    frame = cv2.resize(frame, res)

    #Get bounding boxes and their scores along side with their respective index
    boxes, scores = detect_objects(frame)
    a=0
    b=0
    # Get the video resolution
    #width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
    #height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))
   

    #We ensure that we deal only with the detections with a confidence level greater than 0.55
    for key, value in scores.items():
        if value<0.55:
            boxes.pop(key)

    # Get the first 5 items
    boxes = dict(islice(boxes.items(), 5))

    # No fish detected, skip to the next frame
    if len(boxes) == 0:
        print("No fish detected in this frame.")
        out.write(frame)  # Optionally, write the frame as is
        continue  # Skip the rest of the loop
 
    # If there's a new bounding box detected, initialize its responding kalman tracker
    if len(boxes) > prev_length and len(boxes)<=5:
        for m in range(prev_length, len(boxes)):
            x0, y0, X0, Y0 = boxes[m]  # Accessing bounding box directly
            col_caja.append(colors[m])
            mostrar.append(colors[m])
            id.append(m)
            x = math.ceil(x0)
            y = math.ceil(y0)
            w0 = math.ceil(X0 - x0)
            h0 = math.ceil(Y0 - y0)
            X = np.array([x + w0 / 2])
            Y = np.array([y + h0 / 2])
            DictX[colors[m]] = X
            DictY[colors[m]] = Y
 
            # Generar filtro de kalman para ese objeto
            kalman = kf(dim_x=4, dim_z=2)
            kalman_list.append(kalman)
            kalman_list[-1].F = np.array([[1, 0, dt, 0], [0, 1, 0, dt], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)
            kalman_list[-1].H = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)
            kalman_list[-1].P *= 10
            kalman_list[-1].R = np.diag([1, 1])
            kalman_list[-1].Q = np.eye(4) * 5
 
            medidas.append(np.array([math.ceil(x + w0 / 2), math.ceil(y + h0 / 2)]).T)
            kalman_list[-1].x = np.array([medidas[-1][0], medidas[-1][1], 0, 0]).T
            lost_occurence[m] = 0
        prev_length  = len(boxes)
 
 
    # We loop through the list of filters
    for kalman_id in range(len(kalman_list)):
        bool = False
        
        #Store the distance between bounding boxes 
        distances = np.zeros(len(boxes))

        #Store the center of each bounding boxes 
        obj = np.zeros((len(boxes), 2))
 
      
        for key, value in boxes.items():
            #Center of each bounding box
            obj[key] = [math.ceil(value[0] + (value[2] - value[0]) / 2), math.ceil(value[1] + (value[3] - value[1]) / 2)]

            #Distance between the last position of the filter and each of the bouding box from the current frame
            distances[key] = math.dist(medidas[kalman_id], obj[key])

        # Store the index of  closest bounding box detected
        min_index = np.argmin(distances)
        # Get its position
        posicion = np.array([math.ceil(boxes[min_index][0] + (boxes[min_index][2] - boxes[min_index][0]) / 2),
                             math.ceil(boxes[min_index][1] + (boxes[min_index][3] - boxes[min_index][1]) / 2)])
 
        # We predict the position of the bounding box kalman_id
        kalman_list[kalman_id].predict()
       
        # In case where it's located 40 px away from its previous position the kalman box remain in that previous one
        if distances[min_index] > 40:
                posicion = anteriores[kalman_id]
                lost_occurence[kalman_id]+=1
        else:
            lost_occurence[kalman_id] = 0

        #Dans le cas ou il se soit eloigné pendant une demi seconde (fps/2)
        if kalman_id in lost_occurence and lost_occurence[kalman_id]>=fps/2:
            if len(boxes) == len(prev_box)+1:
                for key, value in boxes.items():
                    if key not in prev_box:
                        posicion = np.array([math.ceil(value[0] + (value[2]- value[0] )/2),math.ceil(value[1] + (value[3]-value[1])/2)])
                        bool = True
            prev_box =boxes 
 
 
        medidas[kalman_id] = posicion.reshape((2, 1))
 
        kalman_list[kalman_id].update(medidas[kalman_id])
 
        prediction = kalman_list[kalman_id].x
        x = prediction[0]
        y = prediction[1]
 
        center = (int(x), int(y))
        W = boxes[min_index][2] - boxes[min_index][0]
        H = boxes[min_index][3] - boxes[min_index][1]
        pt1 = (int(x - W / 2), int(y - H / 2))
        pt2 = (int(x + W / 2), int(y + H / 2))
 
        
        X = np.vstack((DictX[col_caja[kalman_id]], [x]))
        Y = np.vstack((DictY[col_caja[kalman_id]], [y]))
        DictX[col_caja[kalman_id]] = X
        DictY[col_caja[kalman_id]] = Y

        # Draw the center of each kalman box
        cv2.rectangle(frame, pt1, pt2, col_caja[kalman_id], 2, 1)
        cv2.putText(frame, f"{kalman_id}K", (int(x - W / 2), int(y - H / 2) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        #for key, value in boxes.items():
         #   if key == kalman_id:
          #      cv2.putText(frame, f"{key}B", (int(value[0]) +20, int(value[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
 
 
        # Draw the center of each kalman box, if a bb is lost its color is red otherwise it's blue
        if distances[min_index] > 40:
            cv2.circle(frame, (int(posicion[0]), int(posicion[1])), 10, (255, 0, 0), 3)
        else:
            cv2.circle(frame, (int(posicion[0]), int(posicion[1])), 10, (0, 0, 255), 3)
        
        # Draw the trajectory line
        for i in range(1, len(X)):
            cv2.line(frame, (int(X[i-1]), int(Y[i-1])), (int(X[i]), int(Y[i])), col_caja[kalman_id], 1)
           
           
        
        #Handle the case a kalman box has lost it associated bounding box for more than 2 sec
        if lost_occurence[kalman_id]>=fps*2 and bool== False:
            b = 1
            lost_id2 = kalman_id
        else:
         
            for key, value in boxes.items():
                # Check if the distance between the position of the current kalman box and a bb is very small (lower or equal to 5)
                if math.dist( (int(value[0]), int(value[1])), pt1) <=5:
                    associated_bb2.append(key)
       
        if b==1 and kalman_id==len(kalman_list)-1:
            for key, value in boxes.items():
                if key not in associated_bb2:
                    pos2 = np.array([math.ceil(value[0] + (value[2]- value[0] )/2),math.ceil(value[1] + (value[3]-value[1])/2)])
                    medidas[lost_id2] = pos2
                    kalman_list[lost_id2].update(medidas[lost_id2])
                    b=0
    

    
         # Handle the case where two kalman boxes are associated to the same bounding box
        for key, value in boxes.items():
            if math.dist( (int(value[0]), int(value[1])), pt1) <=5:
                if key not in associated_bb.values():
                    associated_bb[kalman_id] = key
                else:
                    a=1
                    lost_id = kalman_id
                    pos_petit = pt1
                    lost_occurence2[lost_id]+=1
                    associated_bb[kalman_id] = key

        #print(f" boxes = {len(boxes)} -> kalman = {len(kalman_list)}")

       
        #Association of one of the two to the untracked bounding box
        if a==1 and kalman_id==len(kalman_list)-1 and lost_occurence2[lost_id]>=fps/2:
    
            first_occurrence = {}
            first_key = None
            second_key = None
            for kb, bb in associated_bb.items():
                if bb in first_occurrence:
                    first_key = first_occurrence[bb]  # Get the first key where this value was seen
                    second_key = kb
                    break
                else:
                    first_occurrence[bb] = kb  # Store the first key where the value appears

           
            for key, value in boxes.items():
                if key not in associated_bb2 :
                    if math.dist( (int(value[0]), int(value[1])), posicion_key[first_key]) < math.dist( (int(value[0]), int(value[1])), posicion_key[second_key]):
                        pos = np.array([math.ceil(value[0] + (value[2]- value[0] )/2),math.ceil(value[1] + (value[3]-value[1])/2)])
                        medidas[first_key] = pos
                        kalman_list[first_key].update(medidas[first_key])
                        a=0
                        lost_occurence2[lost_id]=0
                    else:
                        pos = np.array([math.ceil(value[0] + (value[2]- value[0] )/2),math.ceil(value[1] + (value[3]-value[1])/2)])
                        medidas[second_key] = pos
                        kalman_list[second_key].update(medidas[second_key])
                        a=0
                        lost_occurence2[lost_id]=0

        # We handle the case where at the begining the program detects more kalman box than tha actual number of seabass in the tank
        if  kalman_id==len(kalman_list)-1 and lost_occurence2[lost_id]>=fps*2 and len(kalman_list)<4:
            k=0
            for key, value in boxes.items():
                if key not in associated_bb2 :
                    k=1
            if k==0:
                lost_occurence2[lost_id] =0
                prev_length -=1
                # Remove Kalman filter at index 7
                del kalman_list[lost_id]
                # Adjust other lists to maintain alignment with kalman_list
                del medidas[lost_id]
                del col_caja[lost_id]
                #del DictX[col_caja[lost_id]]
                #del DictY[col_caja[lost_id]]
                continue  # Skip the rest of the loop for kalman_id == 7


            
        #On associe a chaque id sa position, il est tout a la fin pour qu'il contiene la position du frame anterieur, et en cas de collision(a=1) on ne l'actualise pas
        if a==0:
            posicion_key[kalman_id] = pt1
 
    anteriores = medidas
 
    out.write(frame)
 
    cv2.imshow('Video Processing', frame)
 
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

 
out.release()
video.set(cv2.CAP_PROP_POS_FRAMES, 0)
ok, image = video.read()
frame = cv2.resize(image, res)
 
for c in mostrar:
    col = '#%02x%02x%02x' % c
    X = DictX[c]
    Y = DictY[c]
    plt.plot(X, Y, color=col)
    plt.legend(id)
 
plt.imshow(frame)
plt.show()
cv2.destroyAllWindows()
